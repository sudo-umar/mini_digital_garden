Link to [[Models]]
## Gradient Boosting
it is a technique of converting weak learners into a powerful learners. In boosting, each of our new tree is based on the modified version of our original data set.

### Adaboost

The AdaBoost Algorithm begins by training a decision tree in which each observation is assigned an equal weight. After evaluating the first tree, we increase the weights of those observations that are difficult to classify and lower the weights for those that are easy to classify. The second tree is therefore grown on this weighted data.
